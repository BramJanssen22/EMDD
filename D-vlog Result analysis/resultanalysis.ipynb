{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Tokenizer Performance And Fairness Metrics}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      "predictor & blingfire & nltk & spacysm & spacylg & spacytrf \\\\\n",
      "\\midrule\n",
      "\\textbf{depressionTotalF1} & 0.663900 & 0.663900 & 0.886076 & 0.860759 & 0.784314 \\\\\n",
      "\\textbf{normalTotalF1} & 0.000000 & 0.000000 & 0.890244 & 0.865854 & 0.804734 \\\\\n",
      "\\textbf{accuracyTotal} & 0.496894 & 0.496894 & 0.888199 & 0.863354 & 0.795031 \\\\\n",
      "\\textbf{statisticalParity} & NaN & NaN & 0.760321 & 0.760321 & 0.834862 \\\\\n",
      "\\textbf{equalOpportunity} & NaN & NaN & 0.940690 & 0.897931 & 0.833793 \\\\\n",
      "\\textbf{equalisedOdds} & 1.000000 & 1.000000 & 0.982556 & 0.941332 & 0.832223 \\\\\n",
      "\\textbf{equalAccuracy} & 1.340323 & 1.340323 & 0.974429 & 0.933828 & 0.822175 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/results/testresults.csv')\n",
    "\n",
    "# Table for SVM tokenizer Performance and Fairness Metrics\n",
    "SVMTKMetrics = df[['predictor','depressionTotalF1','normalTotalF1','accuracyTotal','statisticalParity','equalOpportunity','equalisedOdds','equalAccuracy']]\n",
    "\n",
    "SVMTKMetrics.to_csv('SVMTKMetricsSVM.csv')\n",
    "\n",
    "SVMTKMetrics = SVMTKMetrics[SVMTKMetrics['predictor'].isin(['blingfire','nltk','spacysm','spacylg','spacytrf'])]\n",
    "SVMTKMetrics.set_index('predictor', inplace=True)\n",
    "SVMTKMetrics = SVMTKMetrics.T\n",
    "\n",
    "latex = SVMTKMetrics.to_latex(\n",
    "    caption='Tokenizer Performance And Fairness Metrics',\n",
    "    index=True,  \n",
    "    header=True, \n",
    "    bold_rows=True, \n",
    "    column_format='lcccccc',\n",
    "    escape=False\n",
    ")\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptom result creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['blingfire','reweightedblingfire','nltk','reweightednltk','spacysm','reweightedspacysm','spacylg','reweightedspacylg','spacytrf','reweightedspacytrf']\n",
    "options = ['Testspacysm']\n",
    "symps = [\"Anxious_Mood\",\"Autonomic_symptoms\",\"Cardiovascular_symptoms\",\"Catatonic_behavior\",\"Decreased_energy_tiredness_fatigue\",\"Depressed_Mood\",\"Gastrointestinal_symptoms\",\"Genitourinary_symptoms\",\"Hyperactivity_agitation\",\"Impulsivity\",\"Inattention\",\"Indecisiveness\",\"Respiratory_symptoms\",\"Suicidal_ideas\",\"Worthlessness_and_guilty\",\"avoidance_of_stimuli\",\"compensatory_behaviors_to_prevent_weight_gain\",\"compulsions\",\"diminished_emotional_expression\",\"do_things_easily_get_painful_consequences\",\"drastical_shift_in_mood_and_energy\",\"fear_about_social_situations\",\"fear_of_gaining_weight\",\"fears_of_being_negatively_evaluated\",\"flight_of_ideas\",\"intrusion_symptoms\",\"loss_of_interest_or_motivation\",\"more_talktive\",\"obsession\",\"panic_fear\",\"pessimism\",\"poor_memory\",\"sleep_disturbance\",\"somatic_muscle\",\"somatic_symptoms_others\",\"somatic_symptoms_sensory\",\"weight_and_appetite_change\",\"Anger_Irritability\"]\n",
    "label = 'depression'\n",
    "\n",
    "for name in options:\n",
    "    df = pd.read_json(f'../data/vectorData/{name}Vectors.json',orient='records', lines=True)\n",
    "    dfm = df.loc[(df['label'] == label) & (df['gender'] == 'm')]\n",
    "    dff = df.loc[(df['label'] == label) & (df['gender'] == 'f')]\n",
    "    vectorsm = dfm[symps]\n",
    "    vectorsf = dff[symps]\n",
    "    metricsm = {\n",
    "    'Mean_M': vectorsm.mean(),\n",
    "    'Std_M': vectorsm.std(),\n",
    "    'Median_M': vectorsm.median(),\n",
    "    'Maximum_M': vectorsm.max(),\n",
    "    'Minimum_M': vectorsm.min(),\n",
    "    '25th Percentile_M': vectorsm.quantile(0.25),\n",
    "    '75th Percentile_M': vectorsm.quantile(0.75),\n",
    "    'Variance_M': vectorsm.var(),\n",
    "    }\n",
    "    metricsf = {\n",
    "    'Mean_F': vectorsf.mean(),\n",
    "    'Std_F': vectorsf.std(),\n",
    "    'Median_F': vectorsf.median(),\n",
    "    'Maximum_F': vectorsf.max(),\n",
    "    'Minimum_F': vectorsf.min(),\n",
    "    '25th Percentile_F': vectorsf.quantile(0.25),\n",
    "    '75th Percentile_F': vectorsf.quantile(0.75),\n",
    "    'Variance_F': vectorsf.var(),\n",
    "    }\n",
    "    metricsm = pd.DataFrame(metricsm)\n",
    "    metricsf = pd.DataFrame(metricsf)\n",
    "    # metricsm = metricsm.T\n",
    "    # metricsf = metricsf.T\n",
    "\n",
    "metricsf.to_csv(f'{label}femaleSymptomMetrics.csv')\n",
    "metricsm.to_csv(f'{label}maleSymptomMetrics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "female_data = pd.read_csv(f'{label}femaleSymptomMetrics.csv', index_col=0)\n",
    "male_data = pd.read_csv(f'{label}maleSymptomMetrics.csv', index_col=0)\n",
    "\n",
    "# Merging dataframes\n",
    "merged_data = female_data.merge(male_data, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculating differences\n",
    "merged_data['Mean_Diff-'] = merged_data['Mean_F'] - merged_data['Mean_M']\n",
    "merged_data['Mean_Diff/'] = merged_data['Mean_F']/merged_data['Mean_M']\n",
    "merged_data['Std_Diff'] = merged_data['Std_F'] - merged_data['Std_M']\n",
    "merged_data['Median_Diff'] = merged_data['Median_F'] - merged_data['Median_M']\n",
    "\n",
    "# Selecting metrics\n",
    "comparison_columns = ['Mean_F', 'Mean_M', 'Mean_Diff-', 'Mean_Diff/',\n",
    "                      'Std_F', 'Std_M','Std_Diff',\n",
    "                      'Median_F', 'Median_M','Median_Diff', \n",
    "                      'Maximum_F', 'Maximum_M', \n",
    "                      'Minimum_F', 'Minimum_M', \n",
    "                    #   '25th Percentile_F', '25th Percentile_M', \n",
    "                    #   '75th Percentile_F', '75th Percentile_M', \n",
    "                    #   'Variance_F', 'Variance_M'\n",
    "                      ]\n",
    "\n",
    "# Creating a summary dataframe for comparison\n",
    "summary_comparison = merged_data[comparison_columns]\n",
    "\n",
    "summary_comparison.to_csv(f'{label}comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ranked comparison\n",
    "sorted_valuesF = summary_comparison.sort_values(by='Mean_F', ascending=False)\n",
    "sorted_valuesM = summary_comparison.sort_values(by='Mean_M', ascending=False)\n",
    "\n",
    "sorted_valuesF['ranking_F'] = range(1,39)\n",
    "sorted_valuesM['ranking_M'] = range(1,39)\n",
    "\n",
    "\n",
    "merged = sorted_valuesM.merge(sorted_valuesF[['ranking_F']], left_index=True, right_index=True, how='right')\n",
    "merged.to_csv('../data/results/symptomResults.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OZP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
