{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import yaml\n",
    "import xopen\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os.path import dirname\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from data import infer_preprocess, cut_sentences\n",
    "from model import Classifier\n",
    "from utils import decide_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batch_size = 64\n",
    "    patient_dir = \"../data/datastoreOZP/dvlog_wtext.json\"\n",
    "    output_dir = \"../../Status_inference_data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ckpt_dir = \"lightning_logs/version_0/checkpoints/epoch=1-step=133.ckpt\"\n",
    "    hparams_dir = os.path.join(dirname(dirname(ckpt_dir)), 'hparams.yaml')\n",
    "    hparams = yaml.load(open(hparams_dir))\n",
    "    max_len = hparams[\"max_len\"]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hparams[\"model_type\"])\n",
    "    clf = Classifier.load_from_checkpoint(ckpt_dir, symps=['uncertain'])\n",
    "    clf.eval()\n",
    "    clf.cuda()\n",
    "    split2dataset = []\n",
    "    \n",
    "    with xopen.xopen(patient_dir) as fi:\n",
    "        for i, line in tqdm(enumerate(fi)):\n",
    "            record = json.loads(line)\n",
    "            aid = \"P\" + str(record['id'])\n",
    "            user_sents = []\n",
    "            sent_bounds = [0]\n",
    "            curr_sid = 0\n",
    "            post_subj = []\n",
    "            for post in record[\"posts\"]:\n",
    "                post_subj.append(decide_subject(post))\n",
    "                sents = cut_sentences(post)\n",
    "                curr_sid += len(sents)\n",
    "                sent_bounds.append(curr_sid)\n",
    "                user_sents.extend(sents)\n",
    "\n",
    "            all_probs = []\n",
    "            for i in range(0, len(user_sents), batch_size):\n",
    "                curr_texts = user_sents[i:i+batch_size]\n",
    "                processed_batch = infer_preprocess(curr_texts, tokenizer, max_len)\n",
    "                for k, v in processed_batch.items():\n",
    "                    processed_batch[k] = v.to(clf.device)\n",
    "                with torch.no_grad():\n",
    "                    logits = clf(processed_batch)\n",
    "                    probs = logits.sigmoid().detach().cpu().numpy()\n",
    "                all_probs.append(probs)\n",
    "            all_probs = np.concatenate(all_probs, 0)\n",
    "\n",
    "            # merge all sentence features into post-level feature by max pooling\n",
    "            all_post_probs = []\n",
    "            for i in range(len(sent_bounds)-1):\n",
    "                lbound, rbound = sent_bounds[i], sent_bounds[i+1]\n",
    "                post_prob = all_probs[lbound:rbound, 0].max()\n",
    "                all_post_probs.append(post_prob)\n",
    "            all_post_probs = np.array(all_post_probs)\n",
    "            post_subj = np.array(post_subj)\n",
    "            data = {\n",
    "                \"id\": aid,\n",
    "                \"diseases\": record[\"diseases\"],\n",
    "                \"uncertain\": all_post_probs,\n",
    "                \"subj\": post_subj\n",
    "            }\n",
    "            split2dataset.append(data)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(split2dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/datastoreOZP/Status_inference_data.csv')\n",
    "df.to_json('../data/datastoreOZP/Status_inference_data.json', orient='records',lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OZP-compatibility",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
