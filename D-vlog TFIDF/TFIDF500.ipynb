{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors and top 500 word ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       features     scores    features    scores     features     scores\n",
      "118    dialogue  25.097472   different  0.667628   depression  11.672804\n",
      "113  depression  19.012485  depressive  0.563564       deeper   0.531270\n",
      "17      anxiety  11.304031      animal  0.365658      anxiety   6.963480\n",
      "416     student  10.044010          su  0.314968        story   0.780988\n",
      "2            __   8.711688        2016  0.408216           __   5.592769\n",
      "417    students   8.507423       sucks  0.666282       stress   0.500953\n",
      "111   depressed   8.192506  depressing  0.407421       debate   1.002802\n",
      "157        feel   6.920789      forces  0.303131      eyebrow   0.553865\n",
      "158     feeling   6.909871      forums  0.331704      eyelash   0.632751\n",
      "190       group   6.498619      hinges  0.319598         gone   0.501632\n",
      "241        know   5.928631        long  0.609346         joey   0.593367\n",
      "283  medication   5.409079      number  0.371076  medications   1.375825\n",
      "475          ve   5.376466      versus  0.374553        views   0.594034\n",
      "69      clemson   4.866419       cause  0.493601        chose   0.771531\n",
      "470  university   4.687033      upside  0.379976          use   2.575190\n",
      "238        just   4.579653          ll  0.321817     isabella   0.552039\n",
      "132         don   4.320961     effects  0.472012       doctor   1.529975\n",
      "314    opinions   4.280775     portion  0.431482       orders   0.515210\n",
      "205        help   4.208933    involved  0.486560         hate   0.530308\n",
      "123  discussion   4.127634     doctors  0.374729     dialogue  15.124229\n",
      "\\begin{table}\n",
      "\\caption{Top 20 TFIDF words}\n",
      "\\begin{tabular}{llrlrlr}\n",
      "\\toprule\n",
      " & features & scores & features & scores & features & scores \\\\\n",
      "\\midrule\n",
      "0 & dialogue & 25.097472 & different & 0.667628 & depression & 11.672804 \\\\\n",
      "1 & depression & 19.012485 & depressive & 0.563564 & deeper & 0.531270 \\\\\n",
      "2 & anxiety & 11.304031 & animal & 0.365658 & anxiety & 6.963480 \\\\\n",
      "3 & student & 10.044010 & su & 0.314968 & story & 0.780988 \\\\\n",
      "4 & __ & 8.711688 & 2016 & 0.408216 & __ & 5.592769 \\\\\n",
      "5 & students & 8.507423 & sucks & 0.666282 & stress & 0.500953 \\\\\n",
      "6 & depressed & 8.192506 & depressing & 0.407421 & debate & 1.002802 \\\\\n",
      "7 & feel & 6.920789 & forces & 0.303131 & eyebrow & 0.553865 \\\\\n",
      "8 & feeling & 6.909871 & forums & 0.331704 & eyelash & 0.632751 \\\\\n",
      "9 & group & 6.498619 & hinges & 0.319598 & gone & 0.501632 \\\\\n",
      "10 & know & 5.928631 & long & 0.609346 & joey & 0.593367 \\\\\n",
      "11 & medication & 5.409079 & number & 0.371076 & medications & 1.375825 \\\\\n",
      "12 & ve & 5.376466 & versus & 0.374553 & views & 0.594034 \\\\\n",
      "13 & clemson & 4.866419 & cause & 0.493601 & chose & 0.771531 \\\\\n",
      "14 & university & 4.687033 & upside & 0.379976 & use & 2.575190 \\\\\n",
      "15 & just & 4.579653 & ll & 0.321817 & isabella & 0.552039 \\\\\n",
      "16 & don & 4.320961 & effects & 0.472012 & doctor & 1.529975 \\\\\n",
      "17 & opinions & 4.280775 & portion & 0.431482 & orders & 0.515210 \\\\\n",
      "18 & help & 4.208933 & involved & 0.486560 & hate & 0.530308 \\\\\n",
      "19 & discussion & 4.127634 & doctors & 0.374729 & dialogue & 15.124229 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('../data/splitData/postdataLinesSplit.json',lines=True)\n",
    "dfm = df.loc[(df['gender'] == 'm')]\n",
    "dff = df.loc[(df['gender'] == 'f')]\n",
    "labels = df['label']\n",
    "labelsm = dfm['label']\n",
    "labelsf = dff['label']\n",
    "\n",
    "posts = []\n",
    "postsm = []\n",
    "postsf = []\n",
    "\n",
    "for row in df['text']:\n",
    "    post = row[0].lower()\n",
    "    posts.append(post)\n",
    "\n",
    "for row in dfm['text']:\n",
    "    post = row[0].lower()\n",
    "    postsm.append(post)\n",
    "\n",
    "for row in dff['text']:\n",
    "    post = row[0].lower()\n",
    "    postsf.append(post)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=True)\n",
    "selector = SelectKBest(chi2, k=500)\n",
    "\n",
    "# select top 500\n",
    "# total\n",
    "vectors = vectorizer.fit_transform(posts)\n",
    "top500Vectors = selector.fit_transform(vectors, labels)\n",
    "\n",
    "mask = selector.get_support()\n",
    "features = vectorizer.get_feature_names_out()[mask]\n",
    "allScores = selector.scores_\n",
    "scores = allScores[mask]\n",
    "\n",
    "# male\n",
    "vectorsm = vectorizer.fit_transform(postsm)\n",
    "top500Vectorsm = selector.fit_transform(vectorsm, labelsm)\n",
    "\n",
    "\n",
    "maskm = selector.get_support()\n",
    "featuresm = vectorizer.get_feature_names_out()[maskm]\n",
    "allScoresm = selector.scores_\n",
    "scoresm = allScoresm[maskm]\n",
    "\n",
    "# female\n",
    "vectorsf = vectorizer.fit_transform(postsf)\n",
    "top500Vectorsf = selector.fit_transform(vectorsf, labelsf)\n",
    "\n",
    "\n",
    "maskf = selector.get_support()\n",
    "featuresf = vectorizer.get_feature_names_out()[maskf]\n",
    "allScoresf = selector.scores_\n",
    "scoresf = allScoresf[maskf]\n",
    "\n",
    "top500Words = pd.DataFrame({'features':features,'scores':scores}).sort_values(by='scores', ascending=False)\n",
    "top500Wordsm = pd.DataFrame({'features':featuresm,'scores':scoresm}).sort_values(by='scores', ascending=False)\n",
    "top500Wordsf = pd.DataFrame({'features':featuresf,'scores':scoresf}).sort_values(by='scores', ascending=False)\n",
    "\n",
    "totaltable = pd.concat([top500Words,top500Wordsm,top500Wordsf], axis=1)\n",
    "print(totaltable.head(20))\n",
    "\n",
    "print(totaltable.head(20).reset_index(drop=True).to_latex(caption='Top 20 TFIDF words',index=True))\n",
    "\n",
    "# create vectors for SVM model\n",
    "vectors = top500Vectors.todense()\n",
    "vector_dicts = []\n",
    "for vector in vectors:\n",
    "    vector_dict = {i: value for i, value in enumerate(vector.tolist()[0])}\n",
    "    vector_dicts.append(vector_dict)\n",
    "\n",
    "vector_df = pd.DataFrame(vector_dicts)\n",
    "df = pd.concat([df, vector_df], axis=1)\n",
    "df.to_json(\"../data/vectorData/TFIDF500Vectors.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight=&#x27;balanced&#x27;, probability=True,\n",
       "                           random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;gamma&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight=&#x27;balanced&#x27;, probability=True,\n",
       "                           random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;gamma&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, probability=True, random_state=99)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, probability=True, random_state=99)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight='balanced', probability=True,\n",
       "                           random_state=99),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/vectorData/TFIDF500Vectors.json', orient='records', lines=True)\n",
    "\n",
    "(df['gender'] == 'm') & (df['split'] == 'train')\n",
    "\n",
    "X_train = df.loc[(df['split'] == 'train'), [str(i) for i in range(500)]]\n",
    "X_test = df.loc[(df['split'] == 'test'), [str(i) for i in range(500)]]\n",
    "# X_testm = df.loc[(df['gender'] == 'm') & (df['split'] == 'test'), [str(i) for i in range(712)]]\n",
    "# X_testf = df.loc[(df['gender'] == 'f') & (df['split'] == 'test'), [str(i) for i in range(712)]]\n",
    "\n",
    "y_train = df.loc[(df['split'] == 'train'), ['label']]\n",
    "y_test = df.loc[(df['split'] == 'test'), ['label']]\n",
    "# y_testm = df.loc[(df['gender'] == 'm') & (df['split'] == 'test'), ['label']]\n",
    "# y_testf = df.loc[(df['gender'] == 'f') & (df['split'] == 'test'), ['label']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "# X_testm = scaler.transform(X_testm)\n",
    "# X_testf = scaler.transform(X_testf)\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "param_grid = {'C': np.logspace(-3, 3, 7),  \n",
    "              'gamma': np.logspace(-3, 3, 7), \n",
    "              'kernel': ['rbf']}  \n",
    "\n",
    "cv = 5\n",
    "scoring = 'accuracy'\n",
    "\n",
    "grid = GridSearchCV(SVC(random_state=99, probability=True, class_weight='balanced'), param_grid, scoring=scoring, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bramb\\AppData\\Local\\Temp\\ipykernel_29828\\445638993.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testSet['prediction'] = y_pred\n",
      "C:\\Users\\bramb\\AppData\\Local\\Temp\\ipykernel_29828\\445638993.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testSet['probability'] = y_prob\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "y_prob = grid.predict_proba(X_test)[:,1]\n",
    "\n",
    "testSet = df.loc[(df['split'] == 'test')]\n",
    "\n",
    "testSet['prediction'] = y_pred\n",
    "testSet['probability'] = y_prob\n",
    "\n",
    "testSet.to_json('../data/predictionData/TFIDF500Pred.json',orient='records',lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OZP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
